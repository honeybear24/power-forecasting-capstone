{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, date, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import canada_holiday\n",
    "import joblib  # To load the scaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from pyhelpers.store import save_fig, save_svg_as_emf\n",
    "import subprocess\n",
    "import  aspose.cells \n",
    "from aspose.cells import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JANNA IS RUNNING!\n",
      "PUB_HourlyConsumptionByFSA_201801_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201802_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201803_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201804_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201805_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201806_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201807_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201808_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201809_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201810_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201811_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201812_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201901_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201902_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201903_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201904_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201905_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201906_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201907_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201908_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201909_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201910_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201911_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_201912_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202001_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202002_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202003_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202004_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202005_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202006_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202007_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202008_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202009_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202010_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202011_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202012_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202101_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202102_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202103_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202104_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202105_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202106_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202107_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202108_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202109_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202110_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202111_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202112_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202201_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202202_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202203_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202204_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202205_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202206_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202207_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202208_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202209_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202210_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202211_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202212_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202301_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202302_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202303_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202304_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202305_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202306_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202307_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202308_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202309_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202310_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202311_v1.csv\n",
      "PUB_HourlyConsumptionByFSA_202312_v1.csv\n"
     ]
    }
   ],
   "source": [
    "#%% Student directory\n",
    "hanad_run = [\"./data\", 1]\n",
    "clover_run = [\"./data\", 2]\n",
    "joseph_laptop_run = [\"C:\\\\Users\\\\sposa\\\\Documents\\\\GitHub\\\\power-forecasting-capstone\\\\data\", 3]\n",
    "joseph_pc_run = [\"D:\\\\Users\\\\Joseph\\\\Documents\\\\GitHub\\\\power-forecasting-capstone\\\\data\", 3]\n",
    "janna_run = [\"../data\", 4]\n",
    "\n",
    "###############################################################################\n",
    "############### MAKE SURE TO CHANGE BEFORE RUNNING CODE #######################\n",
    "###############################################################################\n",
    "# Paste student name_run for whoever is running the code\n",
    "run_student = janna_run\n",
    "if (run_student[1] == joseph_laptop_run[1]):\n",
    "    print(\"JOSEPH IS RUNNING!\")\n",
    "elif (run_student[1] == hanad_run[1]):\n",
    "    print(\"HANAD IS RUNNING!\")\n",
    "elif (run_student[1] == janna_run[1]):\n",
    "    print(\"JANNA IS RUNNING!\")\n",
    "elif (run_student[1] == clover_run[1]):\n",
    "    print(\"CLOVER IS RUNNING!\")\n",
    "else:\n",
    "    print(\"ERROR!! NO ELIGIBLE STUDENT!\")\n",
    "            \n",
    "#%% User input\n",
    "\n",
    "# FSA - Forward Section Area (first 3 characters of Postal Code)\n",
    "#       L8K = Neighborhood in Hamilton (Link to FSA Map: https://www.prospectsinfluential.com/wp-content/uploads/2017/09/Interactive-Canadian-FSA-Map.pdf)\n",
    "fsa_list = ['L9G']\n",
    "\n",
    "# GUI INPUT\n",
    "fsa_chosen = \"L9G\"\n",
    "\n",
    "years = ['2018', '2019', '2020', '2021', '2022', '2023']\n",
    "#years = ['2018']\n",
    "\n",
    "# Jan - 01\n",
    "# Feb - 02\n",
    "# Mar - 03\n",
    "# Apr - 04\n",
    "# May - 05\n",
    "# Jun - 06\n",
    "# Jul - 07\n",
    "# Aug - 08\n",
    "# Sep - 09\n",
    "# Oct - 10\n",
    "# Nov - 11\n",
    "# Dec - 12\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "\n",
    "months_name = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "\n",
    "#%% Input files (PRE-PROCESSING)\n",
    "dirs_inputs = run_student[0]\n",
    "\n",
    "dirs_hourly_consumption_demand = os.path.join(dirs_inputs, \"Hourly_Demand_Data\")\n",
    "\n",
    "###############################################################################\n",
    "# Dictionary for reading in hourly consumption by FSA\n",
    "###############################################################################\n",
    "# FSA -> Year -> Month -> Value\n",
    "hourly_consumption_data_dic_by_month = {}\n",
    "\n",
    "for fsa in fsa_list:\n",
    "    hourly_consumption_data_dic_by_month[fsa] = {} # Initialize FSA dictionary\n",
    "    for year in years:\n",
    "        hourly_consumption_data_dic_by_month[fsa][year] = {} # Initialize yearly dictionary\n",
    "        \n",
    "        for month in months:\n",
    "            hourly_consumption_data_dic_by_month[fsa][year][month] = {} # Initialize monthly dictionary\n",
    "            \n",
    "            # Initialize dataframes to be used\n",
    "            hourly_data_date = pd.DataFrame()\n",
    "            hourly_data_res = pd.DataFrame()\n",
    "            hourly_data_res_fsa = pd.DataFrame()\n",
    "            hourly_data_hour_sum = pd.DataFrame()\n",
    "            \n",
    "            hourly_data_string = \"PUB_HourlyConsumptionByFSA_\"+year+month+\"_v1.csv\"\n",
    "            \n",
    "            # Use try and catch if problems reading input data\n",
    "            try:\n",
    "                # Not cooked yet, we are going to let it COOK below\n",
    "                file_path = os.path.join(dirs_hourly_consumption_demand, hourly_data_string)\n",
    "                hourly_data_raw = pd.read_csv(file_path, skiprows=3, header = 0, usecols= ['FSA', 'DATE', 'HOUR', 'CUSTOMER_TYPE', 'TOTAL_CONSUMPTION'])\n",
    "            except FileNotFoundError: # not all months had a file (for example, 2024 only has up to may)\n",
    "                continue\n",
    "            except ValueError: # skiprows=x does not match the \"normal sequence\" of 3. For example, 2023 08 data had a different skip_row value\n",
    "                hourly_data_raw = pd.read_csv(file_path, skiprows=7, header = 0, usecols= ['FSA', 'DATE', 'HOUR', 'CUSTOMER_TYPE', 'TOTAL_CONSUMPTION'])\n",
    "       \n",
    "            # Convert Date into year, month, day\n",
    "            hourly_data_fix_date = hourly_data_raw\n",
    "            hourly_data_fix_date['DATE'] = pd.to_datetime(hourly_data_raw['DATE'])\n",
    "            hourly_data_fix_date['YEAR'] = hourly_data_fix_date['DATE'].dt.year\n",
    "            hourly_data_fix_date['MONTH'] = hourly_data_fix_date['DATE'].dt.month\n",
    "            hourly_data_fix_date['DAY'] = hourly_data_fix_date['DATE'].dt.day\n",
    "            \n",
    "            # Filter out only residential data\n",
    "            hourly_data_res = hourly_data_fix_date.loc[hourly_data_fix_date['CUSTOMER_TYPE'] == \"Residential\"].reset_index(drop=True)\n",
    "            \n",
    "            # Then filter out by the fsa\n",
    "            hourly_data_res_fsa = hourly_data_res.loc[hourly_data_res['FSA'] == fsa].reset_index(drop=True)\n",
    "            \n",
    "            # Take the sum if fsa has more than 1 date (this is because there are different pay codes in residential loads)\n",
    "            hourly_data_hour_sum = hourly_data_res_fsa.groupby([\"FSA\", \"CUSTOMER_TYPE\", \"YEAR\", \"MONTH\", \"DAY\", \"HOUR\", \"DATE\"]).TOTAL_CONSUMPTION.sum().reset_index()\n",
    "            \n",
    "            \n",
    "            hourly_consumption_data_dic_by_month[fsa][year][month] = hourly_data_hour_sum\n",
    "            \n",
    "            \n",
    "            print(hourly_data_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        FSA       DATE  HOUR CUSTOMER_TYPE  TOTAL_CONSUMPTION  YEAR  MONTH  \\\n",
      "0       M1V 2023-12-01     1   Residential             1152.6  2023     12   \n",
      "1       N6P 2023-12-01     1   Residential             3351.6  2023     12   \n",
      "2       M2K 2023-12-01     1   Residential              671.3  2023     12   \n",
      "3       M1R 2023-12-01     1   Residential             4857.5  2023     12   \n",
      "4       M9V 2023-12-01     1   Residential              162.3  2023     12   \n",
      "...     ...        ...   ...           ...                ...   ...    ...   \n",
      "846745  K0C 2023-12-31    24   Residential             1124.1  2023     12   \n",
      "846746  L7S 2023-12-31    24   Residential             2285.5  2023     12   \n",
      "846747  N8W 2023-12-31    24   Residential              588.0  2023     12   \n",
      "846748  M6B 2023-12-31    24   Residential              363.0  2023     12   \n",
      "846749  N3L 2023-12-31    24   Residential             6534.5  2023     12   \n",
      "\n",
      "        DAY  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "846745   31  \n",
      "846746   31  \n",
      "846747   31  \n",
      "846748   31  \n",
      "846749   31  \n",
      "\n",
      "[846750 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hourly_data_res)\n",
    "output_hourly_data_path = os.path.join(dirs_inputs, \"hourly_data_hour.csv\")\n",
    "hourly_data_res.to_csv(output_hourly_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly data summary saved to ../data\\hourly_data_hour_sum.csv\n"
     ]
    }
   ],
   "source": [
    "# Group by FSA, DATE, and HOUR, then sum the TOTAL_CONSUMPTION\n",
    "hourly_data_hour_sum = hourly_data_res.groupby([\"FSA\", \"DATE\", \"HOUR\"]).agg(\n",
    "    TOTAL_CONSUMPTION=('TOTAL_CONSUMPTION', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Output the hourly_data_hour_sum to a CSV file\n",
    "output_hourly_data_path = os.path.join(dirs_inputs, \"hourly_data_hour_sum.csv\")\n",
    "hourly_data_hour_sum.to_csv(output_hourly_data_path, index=False)\n",
    "\n",
    "print(f\"Hourly data summary saved to {output_hourly_data_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSA summary statistics saved to ../data\\FSA_consumption_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Group by FSA and calculate min, max, and mean of TOTAL_CONSUMPTION\n",
    "fsa_summary = hourly_data_hour_sum.groupby(\"FSA\").agg(\n",
    "    min_consumption=('TOTAL_CONSUMPTION', 'min'),\n",
    "    max_consumption=('TOTAL_CONSUMPTION', 'max'),\n",
    "    avg_consumption=('TOTAL_CONSUMPTION', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Output the FSA summary to a CSV file\n",
    "output_fsa_summary_path = os.path.join(dirs_inputs, \"FSA_consumption_summary.csv\")\n",
    "fsa_summary.to_csv(output_fsa_summary_path, index=False)\n",
    "\n",
    "print(f\"FSA summary statistics saved to {output_fsa_summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to ../data\\FSA_consumption_summary_cleaned.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janna\\AppData\\Local\\Temp\\ipykernel_10112\\1958459033.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Path to the input CSV file\n",
    "output_fsa_summary_path = os.path.join(dirs_inputs, \"FSA_consumption_summary.csv\")  # Existing path\n",
    "# Path to the output CSV file\n",
    "output_cleaned_path = os.path.join(dirs_inputs, \"FSA_consumption_summary_cleaned.csv\")  # New path for cleaned data\n",
    "\n",
    "# Step 1: Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(output_fsa_summary_path)\n",
    "\n",
    "# Step 2: Remove apostrophes from all string entries\n",
    "df = df.applymap(lambda x: x.replace(\"'\", \"\") if isinstance(x, str) else x)\n",
    "\n",
    "# Step 3: Save the cleaned DataFrame back to a new CSV file\n",
    "df.to_csv(output_cleaned_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data saved to {output_cleaned_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
